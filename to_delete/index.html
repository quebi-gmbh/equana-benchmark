<!DOCTYPE html>
<html>
<head>
    <title>WASM MatMul Profiler</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, monospace;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #1a1a2e;
            color: #eee;
        }
        h1 { color: #00d4ff; }
        button {
            background: #00d4ff;
            color: #1a1a2e;
            border: none;
            padding: 12px 24px;
            font-size: 16px;
            cursor: pointer;
            margin: 5px;
            border-radius: 4px;
        }
        button:hover { background: #00a8cc; }
        button:disabled { background: #666; cursor: not-allowed; }
        #output {
            background: #0f0f1a;
            padding: 20px;
            margin-top: 20px;
            border-radius: 8px;
            white-space: pre-wrap;
            font-family: monospace;
            min-height: 200px;
        }
        .result { color: #00ff88; }
        .info { color: #888; }
        .warn { color: #ffaa00; }
    </style>
</head>
<body>
    <h1>WASM Matrix Multiplication Profiler</h1>
    <p class="info">Open DevTools (F12) → Performance tab → Enable "WebAssembly" in settings</p>
    <p class="info">Click "Run Benchmark" then stop recording to see the flame chart</p>

    <div>
        <label>Matrix Size: </label>
        <select id="size">
            <option value="500">500x500</option>
            <option value="1000">1000x1000</option>
            <option value="2000" selected>2000x2000</option>
            <option value="3000">3000x3000</option>
        </select>
        <label style="margin-left:20px">Rounds: </label>
        <select id="rounds">
            <option value="1">1</option>
            <option value="3" selected>3</option>
            <option value="5">5</option>
            <option value="10">10</option>
        </select>
    </div>
    <br>
    <button id="loadBtn" onclick="loadModule()">1. Load WASM Module</button>
    <button id="runBtn" onclick="runBenchmark()" disabled>2. Run WASM Benchmark</button>
    <button id="gpuBtn" onclick="runWebGPU()">3. WebGPU (f32)</button>
    <button id="gpuSplitBtn" onclick="runWebGPUSplitMatmul()">4. WebGPU Split (df64)</button>
    <button id="accuracyBtn" onclick="runAccuracyTest()" disabled>5. Accuracy Test</button>
    <button onclick="checkGPU()" style="background:#666">GPU Status</button>

    <div id="output"><span class="info">Click "Load WASM Module" to start...</span></div>

    <script type="module">
        let wasmModule = null;

        window.log = function(msg, cls = '') {
            const output = document.getElementById('output');
            if (cls) {
                output.innerHTML += `<span class="${cls}">${msg}</span>\n`;
            } else {
                output.innerHTML += msg + '\n';
            }
            output.scrollTop = output.scrollHeight;
        };

        window.clearLog = function() {
            document.getElementById('output').innerHTML = '';
        };

        window.loadModule = async function() {
            clearLog();
            log('Loading WASM module...', 'info');

            try {
                const { default: createMatmulModule } = await import('./matmul.mjs');
                wasmModule = await createMatmulModule();
                log('WASM module loaded!', 'result');
                log(`Functions available: _matmul_f64, _dgemm, _malloc_f64, _free_f64`, 'info');

                document.getElementById('runBtn').disabled = false;
                document.getElementById('accuracyBtn').disabled = false;
            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
            }
        };

        window.runBenchmark = async function() {
            if (!wasmModule) {
                log('Load module first!', 'warn');
                return;
            }

            const N = parseInt(document.getElementById('size').value);
            const ROUNDS = parseInt(document.getElementById('rounds').value);
            const size = N * N;

            clearLog();
            log(`Matrix size: ${N}x${N}`, 'info');
            log(`FLOPS per matmul: ${(2 * N * N * N / 1e9).toFixed(2)} GFLOP`, 'info');
            log(`Rounds: ${ROUNDS}`, 'info');
            log('');

            // Allocate
            log('Allocating matrices...', 'info');
            const ptrA = wasmModule._malloc_f64(size);
            const ptrB = wasmModule._malloc_f64(size);
            const ptrC = wasmModule._malloc_f64(size);

            // Fill with random data
            const heapF64 = wasmModule.HEAPF64;
            const offsetA = ptrA / 8;
            const offsetB = ptrB / 8;

            for (let i = 0; i < size; i++) {
                heapF64[offsetA + i] = Math.random();
                heapF64[offsetB + i] = Math.random();
            }
            log('Matrices initialized with random data', 'info');
            log('');

            // Warmup
            log('Warmup run...', 'info');
            wasmModule._matmul_f64(N, N, N, ptrA, ptrB, ptrC);

            // Timed runs
            log('');
            log('=== Benchmark Results ===', 'result');
            const times = [];
            for (let i = 0; i < ROUNDS; i++) {
                const start = performance.now();
                wasmModule._matmul_f64(N, N, N, ptrA, ptrB, ptrC);
                const elapsed = performance.now() - start;
                times.push(elapsed);

                const gflops = 2 * N * N * N / (elapsed / 1000) / 1e9;
                log(`Round ${i + 1}: ${elapsed.toFixed(2)} ms (${gflops.toFixed(2)} GFLOPS)`);
            }

            const avg = times.reduce((a, b) => a + b) / times.length;
            const avgGflops = 2 * N * N * N / (avg / 1000) / 1e9;
            log('');
            log(`Average: ${avg.toFixed(2)} ms (${avgGflops.toFixed(2)} GFLOPS)`, 'result');

            // Cleanup
            wasmModule._free_f64(ptrA);
            wasmModule._free_f64(ptrB);
            wasmModule._free_f64(ptrC);
            log('');
            log('Memory freed', 'info');
        };

        // WebGPU state
        let gpuDevice = null;
        let gpuPipeline = null;
        let gpuBindGroupLayout = null;
        let gpuWorkgroupSize = 16;

        window.runWebGPU = async function() {
            const N = parseInt(document.getElementById('size').value);
            const ROUNDS = parseInt(document.getElementById('rounds').value);
            const size = N * N;

            clearLog();
            log('=== WebGPU Matrix Multiplication ===', 'result');
            log(`Matrix size: ${N}x${N} (f32)`, 'info');
            log('');

            // Check WebGPU support
            if (!navigator.gpu) {
                log('WebGPU not supported in this browser!', 'warn');
                log('Try Chrome 113+ or Edge 113+', 'info');
                log('', 'info');
                log('To enable WebGPU in Chrome:', 'info');
                log('1. Go to chrome://flags', 'info');
                log('2. Search for "WebGPU"', 'info');
                log('3. Enable "Unsafe WebGPU Support"', 'info');
                log('4. Restart browser', 'info');
                return;
            }

            try {
                // Initialize GPU
                log('Initializing WebGPU...', 'info');

                // Try high-performance GPU first (discrete GPU like RTX 4080)
                let adapter = await navigator.gpu.requestAdapter({
                    powerPreference: 'high-performance'
                });

                // Fallback to any adapter
                if (!adapter) {
                    log('High-performance adapter not found, trying default...', 'info');
                    adapter = await navigator.gpu.requestAdapter();
                }

                // Try with fallback adapter
                if (!adapter) {
                    log('Default adapter not found, trying fallback...', 'info');
                    adapter = await navigator.gpu.requestAdapter({
                        forceFallbackAdapter: true
                    });
                }

                if (!adapter) {
                    log('No GPU adapter found!', 'warn');
                    log('', 'info');
                    log('Troubleshooting:', 'info');
                    log('1. Make sure you are using Chrome 113+ or Edge 113+', 'info');
                    log('2. Go to chrome://flags and enable "Unsafe WebGPU Support"', 'info');
                    log('3. Check chrome://gpu for WebGPU status', 'info');
                    log('4. Ensure GPU drivers are up to date', 'info');
                    log('5. Try running Chrome with --enable-unsafe-webgpu flag', 'info');
                    return;
                }

                // Log adapter info
                const adapterInfo = adapter.info || {};
                gpuDevice = await adapter.requestDevice();
                log(`GPU Adapter: ${adapterInfo.vendor || 'Unknown vendor'}`, 'info');
                log(`GPU Device: ${adapterInfo.device || 'Unknown device'}`, 'info');
                log(`GPU Architecture: ${adapterInfo.architecture || 'Unknown'}`, 'info');

                // Create pipeline
                const { pipeline, bindGroupLayout, workgroupSize } = createMatmulPipeline(gpuDevice, N);
                gpuPipeline = pipeline;
                gpuBindGroupLayout = bindGroupLayout;
                gpuWorkgroupSize = workgroupSize;

                // Create buffers
                const A = new Float32Array(size);
                const B = new Float32Array(size);
                for (let i = 0; i < size; i++) {
                    A[i] = Math.random();
                    B[i] = Math.random();
                }

                const bufferA = gpuDevice.createBuffer({
                    size: A.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferB = gpuDevice.createBuffer({
                    size: B.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferC = gpuDevice.createBuffer({
                    size: size * 4,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
                });
                const uniformBuffer = gpuDevice.createBuffer({
                    size: 16,
                    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
                });

                gpuDevice.queue.writeBuffer(bufferA, 0, A);
                gpuDevice.queue.writeBuffer(bufferB, 0, B);
                gpuDevice.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

                // Warmup (2 rounds)
                log('Warmup (2 rounds)...', 'info');
                await runGPUMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                await runGPUMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);

                // Benchmark
                log('');
                const times = [];
                for (let i = 0; i < ROUNDS; i++) {
                    const start = performance.now();
                    await runGPUMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                    const elapsed = performance.now() - start;
                    times.push(elapsed);

                    const gflops = 2 * N * N * N / (elapsed / 1000) / 1e9;
                    log(`Round ${i + 1}: ${elapsed.toFixed(2)} ms (${gflops.toFixed(2)} GFLOPS)`);
                }

                const avg = times.reduce((a, b) => a + b) / times.length;
                const avgGflops = 2 * N * N * N / (avg / 1000) / 1e9;
                log('');
                log(`Average: ${avg.toFixed(2)} ms (${avgGflops.toFixed(2)} GFLOPS)`, 'result');

                // Cleanup
                bufferA.destroy();
                bufferB.destroy();
                bufferC.destroy();
                uniformBuffer.destroy();

            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
                console.error(e);
            }
        };

        async function runGPUMatmul(bufferA, bufferB, bufferC, uniformBuffer, N) {
            const bindGroup = gpuDevice.createBindGroup({
                layout: gpuBindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = gpuDevice.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(gpuPipeline);
            passEncoder.setBindGroup(0, bindGroup);

            const workgroupsX = Math.ceil(N / gpuWorkgroupSize);
            const workgroupsY = Math.ceil(N / gpuWorkgroupSize);
            passEncoder.dispatchWorkgroups(workgroupsX, workgroupsY);
            passEncoder.end();

            gpuDevice.queue.submit([commandEncoder.finish()]);
            await gpuDevice.queue.onSubmittedWorkDone();
        }

        function createMatmulPipeline(device, N) {
            const workgroupSize = 16;

            const shaderCode = `
                @group(0) @binding(0) var<storage, read> A: array<f32>;
                @group(0) @binding(1) var<storage, read> B: array<f32>;
                @group(0) @binding(2) var<storage, read_write> C: array<f32>;

                struct Uniforms {
                    M: u32,
                    N: u32,
                    K: u32,
                }
                @group(0) @binding(3) var<uniform> uniforms: Uniforms;

                const TILE_SIZE: u32 = ${workgroupSize}u;

                var<workgroup> tileA: array<array<f32, ${workgroupSize}>, ${workgroupSize}>;
                var<workgroup> tileB: array<array<f32, ${workgroupSize}>, ${workgroupSize}>;

                @compute @workgroup_size(${workgroupSize}, ${workgroupSize})
                fn main(
                    @builtin(global_invocation_id) global_id: vec3<u32>,
                    @builtin(local_invocation_id) local_id: vec3<u32>
                ) {
                    let row = global_id.y;
                    let col = global_id.x;
                    let localRow = local_id.y;
                    let localCol = local_id.x;

                    let M = uniforms.M;
                    let N = uniforms.N;
                    let K = uniforms.K;

                    var sum: f32 = 0.0;
                    let numTiles = (K + TILE_SIZE - 1u) / TILE_SIZE;

                    for (var t: u32 = 0u; t < numTiles; t = t + 1u) {
                        let aRow = row;
                        let aCol = t * TILE_SIZE + localCol;
                        if (aRow < M && aCol < K) {
                            tileA[localRow][localCol] = A[aRow * K + aCol];
                        } else {
                            tileA[localRow][localCol] = 0.0;
                        }

                        let bRow = t * TILE_SIZE + localRow;
                        let bCol = col;
                        if (bRow < K && bCol < N) {
                            tileB[localRow][localCol] = B[bRow * N + bCol];
                        } else {
                            tileB[localRow][localCol] = 0.0;
                        }

                        workgroupBarrier();

                        for (var k: u32 = 0u; k < TILE_SIZE; k = k + 1u) {
                            sum = sum + tileA[localRow][k] * tileB[k][localCol];
                        }

                        workgroupBarrier();
                    }

                    if (row < M && col < N) {
                        C[row * N + col] = sum;
                    }
                }
            `;

            const shaderModule = device.createShaderModule({ code: shaderCode });

            const bindGroupLayout = device.createBindGroupLayout({
                entries: [
                    { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                    { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                ]
            });

            const pipeline = device.createComputePipeline({
                layout: device.createPipelineLayout({ bindGroupLayouts: [bindGroupLayout] }),
                compute: { module: shaderModule, entryPoint: 'main' }
            });

            return { pipeline, bindGroupLayout, workgroupSize };
        }

        window.runComparison = async function() {
            clearLog();
            log('=== Comparison: WASM vs WebGPU ===', 'result');
            log('');

            // Run WASM
            log('--- WASM (SIMD) ---', 'info');
            await runBenchmark();

            log('');
            log('--- WebGPU ---', 'info');
            await runWebGPU();
        };

        // ============= Split Matmul (df64 via multiple f32 matmuls) =============
        // Instead of emulating df64 arithmetic on GPU, we:
        // 1. Split A and B into hi/lo components on CPU
        // 2. Compute A.hi*B.hi, A.hi*B.lo, A.lo*B.hi on GPU (3 separate f32 matmuls)
        // 3. Sum the results on CPU in f64 precision

        window.runWebGPUSplitMatmul = async function() {
            const N = parseInt(document.getElementById('size').value);
            const ROUNDS = parseInt(document.getElementById('rounds').value);
            const size = N * N;

            clearLog();
            log('=== WebGPU Split Matmul (df64 via 3x f32 matmuls) ===', 'result');
            log(`Matrix size: ${N}x${N}`, 'info');
            log('Strategy: C = A.hi*B.hi + A.hi*B.lo + A.lo*B.hi', 'info');
            log('');

            if (!navigator.gpu) {
                log('WebGPU not supported!', 'warn');
                return;
            }

            try {
                log('Initializing WebGPU...', 'info');
                const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
                if (!adapter) {
                    log('No GPU adapter found!', 'warn');
                    return;
                }

                const device = await adapter.requestDevice();
                const adapterInfo = adapter.info || {};
                log(`GPU: ${adapterInfo.vendor || 'Unknown'} ${adapterInfo.architecture || ''}`, 'info');

                // Create f32 matmul pipeline (reuse existing)
                const { pipeline, bindGroupLayout } = createMatmulPipeline(device, N);

                // Generate random f64 input matrices and split into hi/lo
                log('Generating and splitting matrices...', 'info');
                const A_hi = new Float32Array(size);
                const A_lo = new Float32Array(size);
                const B_hi = new Float32Array(size);
                const B_lo = new Float32Array(size);

                for (let i = 0; i < size; i++) {
                    const a = Math.random();
                    const b = Math.random();
                    A_hi[i] = Math.fround(a);
                    A_lo[i] = Math.fround(a - A_hi[i]);
                    B_hi[i] = Math.fround(b);
                    B_lo[i] = Math.fround(b - B_hi[i]);
                }

                // Create GPU buffers
                const createBuffer = (data) => {
                    const buf = device.createBuffer({
                        size: data.byteLength,
                        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,
                    });
                    device.queue.writeBuffer(buf, 0, data);
                    return buf;
                };

                const bufA_hi = createBuffer(A_hi);
                const bufA_lo = createBuffer(A_lo);
                const bufB_hi = createBuffer(B_hi);
                const bufB_lo = createBuffer(B_lo);

                // Output buffers for 3 matmuls
                const bufC_hh = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
                const bufC_hl = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
                const bufC_lh = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });

                // Read buffers
                const bufRead_hh = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
                const bufRead_hl = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
                const bufRead_lh = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });

                const uniformBuffer = device.createBuffer({ size: 16, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });
                device.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

                // Helper to run one matmul
                const runMatmul = async (bufA, bufB, bufC) => {
                    const bindGroup = device.createBindGroup({
                        layout: bindGroupLayout,
                        entries: [
                            { binding: 0, resource: { buffer: bufA } },
                            { binding: 1, resource: { buffer: bufB } },
                            { binding: 2, resource: { buffer: bufC } },
                            { binding: 3, resource: { buffer: uniformBuffer } },
                        ]
                    });

                    const commandEncoder = device.createCommandEncoder();
                    const passEncoder = commandEncoder.beginComputePass();
                    passEncoder.setPipeline(pipeline);
                    passEncoder.setBindGroup(0, bindGroup);
                    passEncoder.dispatchWorkgroups(Math.ceil(N / 16), Math.ceil(N / 16));
                    passEncoder.end();
                    device.queue.submit([commandEncoder.finish()]);
                    await device.queue.onSubmittedWorkDone();
                };

                // Warmup
                log('Warmup (2 rounds)...', 'info');
                for (let w = 0; w < 2; w++) {
                    await runMatmul(bufA_hi, bufB_hi, bufC_hh);
                    await runMatmul(bufA_hi, bufB_lo, bufC_hl);
                    await runMatmul(bufA_lo, bufB_hi, bufC_lh);
                }

                // Benchmark
                log('');
                const times = [];
                for (let i = 0; i < ROUNDS; i++) {
                    const start = performance.now();

                    // Run 3 matmuls
                    await runMatmul(bufA_hi, bufB_hi, bufC_hh);
                    await runMatmul(bufA_hi, bufB_lo, bufC_hl);
                    await runMatmul(bufA_lo, bufB_hi, bufC_lh);

                    const elapsed = performance.now() - start;
                    times.push(elapsed);

                    const gflops = 2 * N * N * N / (elapsed / 1000) / 1e9;
                    log(`Round ${i + 1}: ${elapsed.toFixed(2)} ms (${gflops.toFixed(2)} effective GFLOPS, 3x matmuls)`);
                }

                const avg = times.reduce((a, b) => a + b) / times.length;
                const avgGflops = 2 * N * N * N / (avg / 1000) / 1e9;
                log('');
                log(`Average: ${avg.toFixed(2)} ms (${avgGflops.toFixed(2)} effective GFLOPS)`, 'result');
                log('Note: Each round does 3 f32 matmuls, assembly on CPU not timed', 'info');

                // Cleanup
                bufA_hi.destroy(); bufA_lo.destroy();
                bufB_hi.destroy(); bufB_lo.destroy();
                bufC_hh.destroy(); bufC_hl.destroy(); bufC_lh.destroy();
                bufRead_hh.destroy(); bufRead_hl.destroy(); bufRead_lh.destroy();
                uniformBuffer.destroy();
                device.destroy();

            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
                console.error(e);
            }
        };

        window.checkGPU = async function() {
            clearLog();
            log('=== GPU Diagnostics ===', 'result');
            log('');

            // Check navigator.gpu
            log(`navigator.gpu: ${navigator.gpu ? 'AVAILABLE' : 'NOT AVAILABLE'}`, navigator.gpu ? 'result' : 'warn');

            if (!navigator.gpu) {
                log('', 'info');
                log('WebGPU is not available. Possible reasons:', 'warn');
                log('1. Browser does not support WebGPU (need Chrome 113+, Edge 113+, Firefox 121+)', 'info');
                log('2. WebGPU is disabled in browser flags', 'info');
                log('3. Running in an insecure context (need HTTPS or localhost)', 'info');
                log('', 'info');
                log('To enable in Chrome:', 'info');
                log('  1. Go to chrome://flags', 'info');
                log('  2. Search for "WebGPU"', 'info');
                log('  3. Set "Unsafe WebGPU Support" to Enabled', 'info');
                log('  4. Restart Chrome', 'info');
                log('', 'info');
                log('Or run Chrome with: --enable-unsafe-webgpu --enable-features=Vulkan', 'info');
                return;
            }

            // Try to get adapters
            log('', 'info');
            log('Checking available adapters...', 'info');

            try {
                // High performance
                const highPerf = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
                if (highPerf) {
                    const info = highPerf.info || {};
                    log(`High-performance adapter: ${info.device || info.description || 'Found'}`, 'result');
                    log(`  Vendor: ${info.vendor || 'Unknown'}`, 'info');
                    log(`  Architecture: ${info.architecture || 'Unknown'}`, 'info');

                    // Check limits
                    const limits = highPerf.limits;
                    log(`  Max buffer size: ${(limits.maxBufferSize / 1024 / 1024).toFixed(0)} MB`, 'info');
                    log(`  Max workgroup size: ${limits.maxComputeWorkgroupSizeX}x${limits.maxComputeWorkgroupSizeY}`, 'info');
                } else {
                    log('High-performance adapter: NOT FOUND', 'warn');
                }

                // Low power
                const lowPower = await navigator.gpu.requestAdapter({ powerPreference: 'low-power' });
                if (lowPower) {
                    const info = lowPower.info || {};
                    log(`Low-power adapter: ${info.device || info.description || 'Found'}`, 'result');
                } else {
                    log('Low-power adapter: NOT FOUND', 'warn');
                }

                // Fallback
                const fallback = await navigator.gpu.requestAdapter({ forceFallbackAdapter: true });
                if (fallback) {
                    log('Software fallback adapter: Available', 'info');
                } else {
                    log('Software fallback adapter: NOT FOUND', 'info');
                }

                if (!highPerf && !lowPower) {
                    log('', 'info');
                    log('No hardware GPU adapter found!', 'warn');
                    log('', 'info');
                    log('Your chrome://gpu shows Vulkan: Disabled', 'warn');
                    log('WebGPU on Linux requires Vulkan backend.', 'info');
                    log('', 'info');
                    log('Try restarting Chrome with these flags:', 'info');
                    log('', 'info');
                    log('google-chrome --enable-features=Vulkan,UseSkiaRenderer \\', 'result');
                    log('  --enable-unsafe-webgpu \\', 'result');
                    log('  --use-vulkan \\', 'result');
                    log('  --use-angle=vulkan', 'result');
                    log('', 'info');
                    log('Or add to /etc/chromium-browser/customizations/00-extra-options:', 'info');
                    log('  CHROMIUM_FLAGS="--enable-features=Vulkan --use-vulkan"', 'info');
                }

            } catch (e) {
                log(`Error checking adapters: ${e.message}`, 'warn');
            }
        };

        // ============= Double-Float (df64) WebGPU Implementation =============
        // Emulates f64 using two f32 values: value = hi + lo
        // Provides ~48 bits of precision (vs f64's 53 bits)

        let gpuDFDevice = null;
        let gpuDFPipeline = null;
        let gpuDFBindGroupLayout = null;

        window.runWebGPUDoubleFloat = async function() {
            const N = parseInt(document.getElementById('size').value);
            const ROUNDS = parseInt(document.getElementById('rounds').value);
            const size = N * N;

            clearLog();
            log('=== WebGPU Double-Float (df64) Matrix Multiplication ===', 'result');
            log(`Matrix size: ${N}x${N} (emulated f64 via 2xf32)`, 'info');
            log('');

            if (!navigator.gpu) {
                log('WebGPU not supported!', 'warn');
                return;
            }

            try {
                log('Initializing WebGPU...', 'info');
                const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
                if (!adapter) {
                    log('No GPU adapter found!', 'warn');
                    return;
                }

                gpuDFDevice = await adapter.requestDevice();
                const adapterInfo = adapter.info || {};
                log(`GPU: ${adapterInfo.vendor || 'Unknown'} ${adapterInfo.architecture || ''}`, 'info');

                // Create double-float pipeline
                const { pipeline, bindGroupLayout } = createDoubleFloatPipeline(gpuDFDevice, N);
                gpuDFPipeline = pipeline;
                gpuDFBindGroupLayout = bindGroupLayout;

                // Convert f64 to double-float format (hi, lo pairs)
                // Each matrix element becomes 2 floats
                log('Converting to double-float format...', 'info');
                const A_df = new Float32Array(size * 2);
                const B_df = new Float32Array(size * 2);

                for (let i = 0; i < size; i++) {
                    const val = Math.random();
                    // Split f64 into hi + lo where hi + lo ≈ val
                    const hi = Math.fround(val);
                    const lo = Math.fround(val - hi);
                    A_df[i * 2] = hi;
                    A_df[i * 2 + 1] = lo;

                    const val2 = Math.random();
                    const hi2 = Math.fround(val2);
                    const lo2 = Math.fround(val2 - hi2);
                    B_df[i * 2] = hi2;
                    B_df[i * 2 + 1] = lo2;
                }

                const bufferA = gpuDFDevice.createBuffer({
                    size: A_df.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferB = gpuDFDevice.createBuffer({
                    size: B_df.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferC = gpuDFDevice.createBuffer({
                    size: size * 2 * 4, // df64 output
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
                });
                const uniformBuffer = gpuDFDevice.createBuffer({
                    size: 16,
                    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
                });

                gpuDFDevice.queue.writeBuffer(bufferA, 0, A_df);
                gpuDFDevice.queue.writeBuffer(bufferB, 0, B_df);
                gpuDFDevice.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

                // Warmup (2 rounds)
                log('Warmup (2 rounds)...', 'info');
                await runDFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                await runDFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);

                // Benchmark
                log('');
                const times = [];
                for (let i = 0; i < ROUNDS; i++) {
                    const start = performance.now();
                    await runDFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                    const elapsed = performance.now() - start;
                    times.push(elapsed);

                    const gflops = 2 * N * N * N / (elapsed / 1000) / 1e9;
                    log(`Round ${i + 1}: ${elapsed.toFixed(2)} ms (${gflops.toFixed(2)} effective GFLOPS)`);
                }

                const avg = times.reduce((a, b) => a + b) / times.length;
                const avgGflops = 2 * N * N * N / (avg / 1000) / 1e9;
                log('');
                log(`Average: ${avg.toFixed(2)} ms (${avgGflops.toFixed(2)} effective GFLOPS)`, 'result');
                log('', 'info');
                log('Note: df64 uses ~10x more FLOPs internally for emulation', 'info');

                // Cleanup
                bufferA.destroy();
                bufferB.destroy();
                bufferC.destroy();
                uniformBuffer.destroy();

            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
                console.error(e);
            }
        };

        async function runDFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N) {
            const bindGroup = gpuDFDevice.createBindGroup({
                layout: gpuDFBindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = gpuDFDevice.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(gpuDFPipeline);
            passEncoder.setBindGroup(0, bindGroup);

            const workgroupSize = 8; // Smaller due to register pressure
            const workgroupsX = Math.ceil(N / workgroupSize);
            const workgroupsY = Math.ceil(N / workgroupSize);
            passEncoder.dispatchWorkgroups(workgroupsX, workgroupsY);
            passEncoder.end();

            gpuDFDevice.queue.submit([commandEncoder.finish()]);
            await gpuDFDevice.queue.onSubmittedWorkDone();
        }

        function createDoubleFloatPipeline(device, N) {
            const workgroupSize = 8; // Reduced for register pressure

            // Double-float arithmetic shader
            // Based on Dekker's algorithms and Knuth's TwoSum
            const shaderCode = `
                // A and B store pairs of (hi, lo) for each element
                @group(0) @binding(0) var<storage, read> A: array<f32>;
                @group(0) @binding(1) var<storage, read> B: array<f32>;
                @group(0) @binding(2) var<storage, read_write> C: array<f32>;

                struct Uniforms {
                    M: u32,
                    N: u32,
                    K: u32,
                }
                @group(0) @binding(3) var<uniform> uniforms: Uniforms;

                // Double-float type: hi + lo ≈ true value
                struct df64 {
                    hi: f32,
                    lo: f32,
                }

                // TwoSum using Knuth's algorithm
                // The key insight: we need to prevent a-(s-v) from being optimized to b
                // Use explicit variable assignments
                fn twoSum(a: f32, b: f32) -> df64 {
                    var s: f32 = a + b;
                    var a_prime: f32 = s - b;
                    var b_prime: f32 = s - a_prime;
                    var delta_a: f32 = a - a_prime;
                    var delta_b: f32 = b - b_prime;
                    var e: f32 = delta_a + delta_b;
                    return df64(s, e);
                }

                // QuickTwoSum: assumes |a| >= |b|
                fn quickTwoSum(a: f32, b: f32) -> df64 {
                    var s: f32 = a + b;
                    var e: f32 = b - (s - a);
                    return df64(s, e);
                }

                // TwoProd using Dekker's algorithm
                fn twoProd(a: f32, b: f32) -> df64 {
                    var p: f32 = a * b;

                    // Veltkamp split: split into high and low parts
                    // For f32 with 24-bit mantissa, use 2^12 + 1 = 4097
                    var ca: f32 = 4097.0 * a;
                    var ah: f32 = ca - (ca - a);
                    var al: f32 = a - ah;

                    var cb: f32 = 4097.0 * b;
                    var bh: f32 = cb - (cb - b);
                    var bl: f32 = b - bh;

                    // Compute error term
                    var r1: f32 = ah * bh;
                    var r2: f32 = r1 - p;
                    var r3: f32 = ah * bl;
                    var r4: f32 = al * bh;
                    var r5: f32 = al * bl;
                    var e: f32 = r2 + r3 + r4 + r5;

                    return df64(p, e);
                }

                // Add two double-floats
                fn df_add(a: df64, b: df64) -> df64 {
                    var s: df64 = twoSum(a.hi, b.hi);
                    var t: df64 = twoSum(a.lo, b.lo);
                    var c: df64 = quickTwoSum(s.hi, s.lo + t.hi);
                    c = quickTwoSum(c.hi, t.lo + c.lo);
                    return c;
                }

                // Multiply two double-floats
                fn df_mul(a: df64, b: df64) -> df64 {
                    var p: df64 = twoProd(a.hi, b.hi);
                    var e: f32 = p.lo + a.hi * b.lo + a.lo * b.hi;
                    return quickTwoSum(p.hi, e);
                }

                // Load double-float from array (interleaved hi, lo)
                fn df_load(arr: ptr<storage, array<f32>, read>, idx: u32) -> df64 {
                    return df64((*arr)[idx * 2u], (*arr)[idx * 2u + 1u]);
                }

                const TILE_SIZE: u32 = ${workgroupSize}u;

                @compute @workgroup_size(${workgroupSize}, ${workgroupSize})
                fn main(
                    @builtin(global_invocation_id) global_id: vec3<u32>,
                    @builtin(local_invocation_id) local_id: vec3<u32>
                ) {
                    let row = global_id.y;
                    let col = global_id.x;

                    let M = uniforms.M;
                    let N = uniforms.N;
                    let K = uniforms.K;

                    if (row >= M || col >= N) {
                        return;
                    }

                    // Accumulator in double-float
                    var sum = df64(0.0, 0.0);

                    // Simple loop
                    for (var k: u32 = 0u; k < K; k = k + 1u) {
                        let a = df_load(&A, row * K + k);
                        let b = df_load(&B, k * N + col);
                        let prod = df_mul(a, b);
                        sum = df_add(sum, prod);
                    }

                    // Store result as double-float
                    let outIdx = row * N + col;
                    C[outIdx * 2u] = sum.hi;
                    C[outIdx * 2u + 1u] = sum.lo;
                }
            `;

            const shaderModule = device.createShaderModule({ code: shaderCode });

            const bindGroupLayout = device.createBindGroupLayout({
                entries: [
                    { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                    { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                ]
            });

            const pipeline = device.createComputePipeline({
                layout: device.createPipelineLayout({ bindGroupLayouts: [bindGroupLayout] }),
                compute: { module: shaderModule, entryPoint: 'main' }
            });

            return { pipeline, bindGroupLayout };
        }

        // ============= Triple-Float (tf64) WebGPU Implementation =============
        // Emulates f64+ using three f32 values: value = hi + mid + lo
        // Provides ~72 bits of precision (exceeds f64's 53 bits)

        let gpuTFDevice = null;
        let gpuTFPipeline = null;
        let gpuTFBindGroupLayout = null;

        window.runWebGPUTripleFloat = async function() {
            const N = parseInt(document.getElementById('size').value);
            const ROUNDS = parseInt(document.getElementById('rounds').value);
            const size = N * N;

            clearLog();
            log('=== WebGPU Triple-Float (tf64) Matrix Multiplication ===', 'result');
            log(`Matrix size: ${N}x${N} (emulated f64+ via 3xf32, ~72-bit precision)`, 'info');
            log('');

            if (!navigator.gpu) {
                log('WebGPU not supported!', 'warn');
                return;
            }

            try {
                log('Initializing WebGPU...', 'info');
                const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
                if (!adapter) {
                    log('No GPU adapter found!', 'warn');
                    return;
                }

                gpuTFDevice = await adapter.requestDevice();
                const adapterInfo = adapter.info || {};
                log(`GPU: ${adapterInfo.vendor || 'Unknown'} ${adapterInfo.architecture || ''}`, 'info');

                // Create triple-float pipeline
                const { pipeline, bindGroupLayout } = createTripleFloatPipeline(gpuTFDevice, N);
                gpuTFPipeline = pipeline;
                gpuTFBindGroupLayout = bindGroupLayout;

                // Convert f64 to triple-float format (hi, mid, lo triples)
                log('Converting to triple-float format...', 'info');
                const A_tf = new Float32Array(size * 3);
                const B_tf = new Float32Array(size * 3);

                for (let i = 0; i < size; i++) {
                    // Split f64 into hi + mid + lo
                    const val = Math.random();
                    const hi = Math.fround(val);
                    const r1 = val - hi;
                    const mid = Math.fround(r1);
                    const lo = Math.fround(r1 - mid);
                    A_tf[i * 3] = hi;
                    A_tf[i * 3 + 1] = mid;
                    A_tf[i * 3 + 2] = lo;

                    const val2 = Math.random();
                    const hi2 = Math.fround(val2);
                    const r2 = val2 - hi2;
                    const mid2 = Math.fround(r2);
                    const lo2 = Math.fround(r2 - mid2);
                    B_tf[i * 3] = hi2;
                    B_tf[i * 3 + 1] = mid2;
                    B_tf[i * 3 + 2] = lo2;
                }

                const bufferA = gpuTFDevice.createBuffer({
                    size: A_tf.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferB = gpuTFDevice.createBuffer({
                    size: B_tf.byteLength,
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
                });
                const bufferC = gpuTFDevice.createBuffer({
                    size: size * 3 * 4, // tf64 output
                    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
                });
                const uniformBuffer = gpuTFDevice.createBuffer({
                    size: 16,
                    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
                });

                gpuTFDevice.queue.writeBuffer(bufferA, 0, A_tf);
                gpuTFDevice.queue.writeBuffer(bufferB, 0, B_tf);
                gpuTFDevice.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

                // Warmup (2 rounds)
                log('Warmup (2 rounds)...', 'info');
                await runTFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                await runTFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);

                // Benchmark
                log('');
                const times = [];
                for (let i = 0; i < ROUNDS; i++) {
                    const start = performance.now();
                    await runTFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N);
                    const elapsed = performance.now() - start;
                    times.push(elapsed);

                    const gflops = 2 * N * N * N / (elapsed / 1000) / 1e9;
                    log(`Round ${i + 1}: ${elapsed.toFixed(2)} ms (${gflops.toFixed(2)} effective GFLOPS)`);
                }

                const avg = times.reduce((a, b) => a + b) / times.length;
                const avgGflops = 2 * N * N * N / (avg / 1000) / 1e9;
                log('');
                log(`Average: ${avg.toFixed(2)} ms (${avgGflops.toFixed(2)} effective GFLOPS)`, 'result');
                log('', 'info');
                log('Note: tf64 provides ~72-bit precision (exceeds f64)', 'info');
                log('Internal FLOPs: ~25x more than f32 for full precision', 'info');

                // Cleanup
                bufferA.destroy();
                bufferB.destroy();
                bufferC.destroy();
                uniformBuffer.destroy();

            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
                console.error(e);
            }
        };

        async function runTFMatmul(bufferA, bufferB, bufferC, uniformBuffer, N) {
            const bindGroup = gpuTFDevice.createBindGroup({
                layout: gpuTFBindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = gpuTFDevice.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(gpuTFPipeline);
            passEncoder.setBindGroup(0, bindGroup);

            const workgroupSize = 8;
            const workgroupsX = Math.ceil(N / workgroupSize);
            const workgroupsY = Math.ceil(N / workgroupSize);
            passEncoder.dispatchWorkgroups(workgroupsX, workgroupsY);
            passEncoder.end();

            gpuTFDevice.queue.submit([commandEncoder.finish()]);
            await gpuTFDevice.queue.onSubmittedWorkDone();
        }

        function createTripleFloatPipeline(device, N) {
            const workgroupSize = 8;

            // Triple-float arithmetic shader
            // Based on Priest's algorithms for triple-word arithmetic
            const shaderCode = `
                @group(0) @binding(0) var<storage, read> A: array<f32>;
                @group(0) @binding(1) var<storage, read> B: array<f32>;
                @group(0) @binding(2) var<storage, read_write> C: array<f32>;

                struct Uniforms {
                    M: u32,
                    N: u32,
                    K: u32,
                }
                @group(0) @binding(3) var<uniform> uniforms: Uniforms;

                // Triple-float type: hi + mid + lo ≈ true value
                struct tf64 {
                    hi: f32,
                    mid: f32,
                    lo: f32,
                }

                // Use bitcast to prevent compiler from optimizing away operations
                fn noopt(x: f32) -> f32 {
                    return bitcast<f32>(bitcast<u32>(x));
                }

                // TwoSum: exact sum of two floats
                fn twoSum(a: f32, b: f32) -> vec2<f32> {
                    let s = noopt(a + b);
                    let v = noopt(s - a);
                    let e = noopt(noopt(a - noopt(s - v)) + noopt(b - v));
                    return vec2<f32>(s, e);
                }

                // QuickTwoSum: when |a| >= |b|
                fn quickTwoSum(a: f32, b: f32) -> vec2<f32> {
                    let s = noopt(a + b);
                    let e = noopt(b - noopt(s - a));
                    return vec2<f32>(s, e);
                }

                // TwoProd: exact product using Dekker splitting
                fn twoProd(a: f32, b: f32) -> vec2<f32> {
                    let p = noopt(a * b);
                    let c = noopt(4097.0 * a);
                    let ah = noopt(c - noopt(c - a));
                    let al = noopt(a - ah);
                    let d = noopt(4097.0 * b);
                    let bh = noopt(d - noopt(d - b));
                    let bl = noopt(b - bh);
                    let e1 = noopt(noopt(ah * bh) - p);
                    let e2 = noopt(ah * bl);
                    let e3 = noopt(al * bh);
                    let e4 = noopt(al * bl);
                    let e = noopt(noopt(noopt(e1 + e2) + e3) + e4);
                    return vec2<f32>(p, e);
                }

                // ThreeSum: sum three floats with full precision
                fn threeSum(a: f32, b: f32, c: f32) -> vec3<f32> {
                    let t1 = twoSum(a, b);
                    let t2 = twoSum(t1.x, c);
                    let t3 = twoSum(t1.y, t2.y);
                    return vec3<f32>(t2.x, t3.x, t3.y);
                }

                // Renormalize triple-float to canonical form
                fn tf_renorm(a: tf64) -> tf64 {
                    let s1 = quickTwoSum(a.mid, a.lo);
                    let s2 = quickTwoSum(a.hi, s1.x);
                    let s3 = quickTwoSum(s2.x, s2.y + s1.y);
                    return tf64(s3.x, s3.y, 0.0);
                }

                // Add two triple-floats
                fn tf_add(a: tf64, b: tf64) -> tf64 {
                    // Add component-wise with carry propagation
                    let s0 = twoSum(a.hi, b.hi);
                    let s1 = twoSum(a.mid, b.mid);
                    let s2 = a.lo + b.lo;

                    // Propagate carries
                    let c0 = twoSum(s0.y, s1.x);
                    let c1 = c0.y + s1.y + s2;

                    // Renormalize
                    let r1 = quickTwoSum(s0.x, c0.x);
                    let r2 = quickTwoSum(r1.y, c1);

                    return tf64(r1.x, r2.x, r2.y);
                }

                // Multiply two triple-floats (simplified - keeps ~72 bits)
                fn tf_mul(a: tf64, b: tf64) -> tf64 {
                    // Main product: hi * hi
                    let p0 = twoProd(a.hi, b.hi);

                    // Cross terms: hi*mid + mid*hi
                    let p1 = twoProd(a.hi, b.mid);
                    let p2 = twoProd(a.mid, b.hi);

                    // Lower terms (contribute to lo)
                    let p3 = a.hi * b.lo + a.mid * b.mid + a.lo * b.hi;

                    // Accumulate
                    let s1 = twoSum(p0.y, p1.x);
                    let s2 = twoSum(s1.x, p2.x);
                    let lo = s1.y + s2.y + p1.y + p2.y + p3;

                    // Renormalize
                    let r1 = quickTwoSum(p0.x, s2.x);
                    let r2 = quickTwoSum(r1.y, lo);

                    return tf64(r1.x, r2.x, r2.y);
                }

                // Load triple-float from array
                fn tf_load(arr: ptr<storage, array<f32>, read>, idx: u32) -> tf64 {
                    return tf64(
                        (*arr)[idx * 3u],
                        (*arr)[idx * 3u + 1u],
                        (*arr)[idx * 3u + 2u]
                    );
                }

                const TILE_SIZE: u32 = ${workgroupSize}u;

                @compute @workgroup_size(${workgroupSize}, ${workgroupSize})
                fn main(
                    @builtin(global_invocation_id) global_id: vec3<u32>,
                    @builtin(local_invocation_id) local_id: vec3<u32>
                ) {
                    let row = global_id.y;
                    let col = global_id.x;

                    let M = uniforms.M;
                    let N = uniforms.N;
                    let K = uniforms.K;

                    if (row >= M || col >= N) {
                        return;
                    }

                    // Accumulator in triple-float
                    var sum = tf64(0.0, 0.0, 0.0);

                    for (var k: u32 = 0u; k < K; k = k + 1u) {
                        let a = tf_load(&A, row * K + k);
                        let b = tf_load(&B, k * N + col);
                        let prod = tf_mul(a, b);
                        sum = tf_add(sum, prod);
                    }

                    // Store result
                    let outIdx = row * N + col;
                    C[outIdx * 3u] = sum.hi;
                    C[outIdx * 3u + 1u] = sum.mid;
                    C[outIdx * 3u + 2u] = sum.lo;
                }
            `;

            const shaderModule = device.createShaderModule({ code: shaderCode });

            const bindGroupLayout = device.createBindGroupLayout({
                entries: [
                    { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
                    { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                    { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                ]
            });

            const pipeline = device.createComputePipeline({
                layout: device.createPipelineLayout({ bindGroupLayouts: [bindGroupLayout] }),
                compute: { module: shaderModule, entryPoint: 'main' }
            });

            return { pipeline, bindGroupLayout };
        }

        // ============= Accuracy Test =============
        // Compares all variants against WASM f64 reference

        window.runAccuracyTest = async function() {
            if (!wasmModule) {
                log('Load WASM module first!', 'warn');
                return;
            }

            const N = parseInt(document.getElementById('size').value);
            const size = N * N;

            clearLog();

            try {
            log('=== Accuracy Test: All Variants vs WASM f64 Reference ===', 'result');
            log(`Matrix size: ${N}x${N}`, 'info');
            log('');

            // Check WebGPU
            if (!navigator.gpu) {
                log('WebGPU not available!', 'warn');
                return;
            }

            const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
            if (!adapter) {
                log('No GPU adapter found!', 'warn');
                return;
            }
            const device = await adapter.requestDevice();

            // Generate random input matrices
            // All methods use same f32-precision inputs for fair comparison
            // The difference will be in accumulation precision
            log('Generating random matrices (f32 precision for fair comparison)...', 'info');
            const A_f64 = new Float64Array(size);
            const B_f64 = new Float64Array(size);
            for (let i = 0; i < size; i++) {
                A_f64[i] = Math.fround(Math.random());
                B_f64[i] = Math.fround(Math.random());
            }

            // ===== 1. WASM f64 Reference =====
            log('');
            log('--- Computing WASM f64 Reference ---', 'info');

            // Allow UI to update before blocking WASM call
            await new Promise(r => setTimeout(r, 50));

            const ptrA = wasmModule._malloc_f64(size);
            const ptrB = wasmModule._malloc_f64(size);
            const ptrC = wasmModule._malloc_f64(size);

            wasmModule.HEAPF64.set(A_f64, ptrA / 8);
            wasmModule.HEAPF64.set(B_f64, ptrB / 8);

            log('Running WASM matmul_f64...', 'info');
            await new Promise(r => setTimeout(r, 10));

            const wasmStart = performance.now();
            wasmModule._matmul_f64(N, N, N, ptrA, ptrB, ptrC);
            const wasmTime = performance.now() - wasmStart;

            const C_wasm = new Float64Array(size);
            C_wasm.set(wasmModule.HEAPF64.subarray(ptrC / 8, ptrC / 8 + size));

            wasmModule._free_f64(ptrA);
            wasmModule._free_f64(ptrB);
            wasmModule._free_f64(ptrC);

            const wasmGflops = 2 * N * N * N / (wasmTime / 1000) / 1e9;
            log(`WASM f64: ${wasmTime.toFixed(2)} ms (${wasmGflops.toFixed(2)} GFLOPS)`, 'result');

            // ===== 2. WebGPU f32 =====
            log('');
            log('--- Computing WebGPU f32 ---', 'info');

            // f32 uses the same inputs (already f32 precision)
            const A_f32 = new Float32Array(size);
            const B_f32 = new Float32Array(size);
            for (let i = 0; i < size; i++) {
                A_f32[i] = A_f64[i];
                B_f32[i] = B_f64[i];
            }

            const C_f32 = await runF32Matmul(device, A_f32, B_f32, N);
            const f32Error = computeError(C_wasm, C_f32, 1);
            log(`WebGPU f32 avg rel error: ${f32Error.toExponential(6)}`, f32Error < 1e-5 ? 'result' : 'warn');

            // ===== 3. WebGPU df64 =====
            log('');
            log('--- Computing WebGPU df64 (double-float) ---', 'info');

            // Convert to df64 format
            // Inputs are already f32 precision, so lo = 0
            const A_df = new Float32Array(size * 2);
            const B_df = new Float32Array(size * 2);
            for (let i = 0; i < size; i++) {
                A_df[i * 2] = A_f64[i];     // hi
                A_df[i * 2 + 1] = 0;         // lo = 0 (no residual since input is f32)

                B_df[i * 2] = B_f64[i];
                B_df[i * 2 + 1] = 0;
            }

            const C_df = await runDF64Matmul(device, A_df, B_df, N);

            // Debug: check if lo component has meaningful values
            let loSum = 0, hiSum = 0, loNonZero = 0;
            for (let i = 0; i < Math.min(1000, size); i++) {
                hiSum += Math.abs(C_df[i * 2]);
                loSum += Math.abs(C_df[i * 2 + 1]);
                if (C_df[i * 2 + 1] !== 0) loNonZero++;
            }
            log(`  Debug: avg |hi|=${(hiSum/1000).toExponential(3)}, avg |lo|=${(loSum/1000).toExponential(3)}, non-zero lo: ${loNonZero}/1000`, 'info');

            const df64Error = computeError(C_wasm, C_df, 2);
            log(`WebGPU df64 avg rel error: ${df64Error.toExponential(6)}`, df64Error < 1e-9 ? 'result' : 'warn');

            // ===== 4. WebGPU tf64 =====
            log('');
            log('--- Computing WebGPU tf64 (triple-float) ---', 'info');

            // Convert to tf64 format
            // Inputs are already f32 precision, so mid = lo = 0
            const A_tf = new Float32Array(size * 3);
            const B_tf = new Float32Array(size * 3);
            for (let i = 0; i < size; i++) {
                A_tf[i * 3] = A_f64[i];     // hi
                A_tf[i * 3 + 1] = 0;         // mid = 0
                A_tf[i * 3 + 2] = 0;         // lo = 0

                B_tf[i * 3] = B_f64[i];
                B_tf[i * 3 + 1] = 0;
                B_tf[i * 3 + 2] = 0;
            }

            const C_tf = await runTF64Matmul(device, A_tf, B_tf, N);
            const tf64Error = computeError(C_wasm, C_tf, 3);
            log(`WebGPU tf64 avg rel error: ${tf64Error.toExponential(6)}`, tf64Error < 1e-13 ? 'result' : 'warn');

            // ===== Summary =====
            log('');
            log('=== Summary ===', 'result');
            log(`Reference: WASM f64 (53-bit mantissa)`, 'info');
            log(`Error metric: (1/N²) × Σ|2(a-b)/(a+b)|  (avg relative error)`, 'info');
            log('');
            log(`f32  (~24-bit):  avg rel error = ${f32Error.toExponential(4)}`, 'info');
            log(`df64 (~48-bit):  avg rel error = ${df64Error.toExponential(4)}`, 'info');
            log(`tf64 (~72-bit):  avg rel error = ${tf64Error.toExponential(4)}`, 'info');
            log('');

            // Relative comparison
            const f32_vs_df = f32Error / df64Error;
            const df_vs_tf = df64Error / tf64Error;
            log(`df64 is ${f32_vs_df.toExponential(2)}x more accurate than f32`, 'info');
            log(`tf64 is ${df_vs_tf.toExponential(2)}x more accurate than df64`, 'info');

            device.destroy();

            } catch (e) {
                log(`Error: ${e.message}`, 'warn');
                console.error(e);
            }
        };

        // Compute average relative error: (1/N²) * Σ |2*(a-b)/(a+b)|
        function computeError(ref_f64, result, componentsPerElement) {
            const size = ref_f64.length;
            let totalError = 0;

            for (let i = 0; i < size; i++) {
                let computed;
                if (componentsPerElement === 1) {
                    // f32 - direct value
                    computed = result[i];
                } else if (componentsPerElement === 2) {
                    // df64 - hi + lo
                    computed = result[i * 2] + result[i * 2 + 1];
                } else if (componentsPerElement === 3) {
                    // tf64 - hi + mid + lo
                    computed = result[i * 3] + result[i * 3 + 1] + result[i * 3 + 2];
                }

                const a = ref_f64[i];
                const b = computed;
                const sum = a + b;

                // Avoid division by zero
                if (Math.abs(sum) > 1e-300) {
                    totalError += Math.abs(2 * (a - b) / sum);
                }
            }

            return totalError / size;
        }

        // Helper: Run f32 matmul and return result
        async function runF32Matmul(device, A, B, N) {
            const size = N * N;
            const { pipeline, bindGroupLayout } = createMatmulPipeline(device, N);

            const bufferA = device.createBuffer({ size: A.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferB = device.createBuffer({ size: B.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferC = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
            const bufferRead = device.createBuffer({ size: size * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
            const uniformBuffer = device.createBuffer({ size: 16, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });

            device.queue.writeBuffer(bufferA, 0, A);
            device.queue.writeBuffer(bufferB, 0, B);
            device.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

            const bindGroup = device.createBindGroup({
                layout: bindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = device.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(pipeline);
            passEncoder.setBindGroup(0, bindGroup);
            passEncoder.dispatchWorkgroups(Math.ceil(N / 16), Math.ceil(N / 16));
            passEncoder.end();
            commandEncoder.copyBufferToBuffer(bufferC, 0, bufferRead, 0, size * 4);
            device.queue.submit([commandEncoder.finish()]);

            await bufferRead.mapAsync(GPUMapMode.READ);
            const result = new Float32Array(bufferRead.getMappedRange().slice(0));
            bufferRead.unmap();

            bufferA.destroy(); bufferB.destroy(); bufferC.destroy(); bufferRead.destroy(); uniformBuffer.destroy();
            return result;
        }

        // Helper: Run df64 matmul and return result
        async function runDF64Matmul(device, A_df, B_df, N) {
            const size = N * N;
            const { pipeline, bindGroupLayout } = createDoubleFloatPipeline(device, N);

            const bufferA = device.createBuffer({ size: A_df.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferB = device.createBuffer({ size: B_df.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferC = device.createBuffer({ size: size * 2 * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
            const bufferRead = device.createBuffer({ size: size * 2 * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
            const uniformBuffer = device.createBuffer({ size: 16, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });

            device.queue.writeBuffer(bufferA, 0, A_df);
            device.queue.writeBuffer(bufferB, 0, B_df);
            device.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

            const bindGroup = device.createBindGroup({
                layout: bindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = device.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(pipeline);
            passEncoder.setBindGroup(0, bindGroup);
            passEncoder.dispatchWorkgroups(Math.ceil(N / 8), Math.ceil(N / 8));
            passEncoder.end();
            commandEncoder.copyBufferToBuffer(bufferC, 0, bufferRead, 0, size * 2 * 4);
            device.queue.submit([commandEncoder.finish()]);

            await bufferRead.mapAsync(GPUMapMode.READ);
            const result = new Float32Array(bufferRead.getMappedRange().slice(0));
            bufferRead.unmap();

            bufferA.destroy(); bufferB.destroy(); bufferC.destroy(); bufferRead.destroy(); uniformBuffer.destroy();
            return result;
        }

        // Helper: Run tf64 matmul and return result
        async function runTF64Matmul(device, A_tf, B_tf, N) {
            const size = N * N;
            const { pipeline, bindGroupLayout } = createTripleFloatPipeline(device, N);

            const bufferA = device.createBuffer({ size: A_tf.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferB = device.createBuffer({ size: B_tf.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
            const bufferC = device.createBuffer({ size: size * 3 * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
            const bufferRead = device.createBuffer({ size: size * 3 * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
            const uniformBuffer = device.createBuffer({ size: 16, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });

            device.queue.writeBuffer(bufferA, 0, A_tf);
            device.queue.writeBuffer(bufferB, 0, B_tf);
            device.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([N, N, N, 0]));

            const bindGroup = device.createBindGroup({
                layout: bindGroupLayout,
                entries: [
                    { binding: 0, resource: { buffer: bufferA } },
                    { binding: 1, resource: { buffer: bufferB } },
                    { binding: 2, resource: { buffer: bufferC } },
                    { binding: 3, resource: { buffer: uniformBuffer } },
                ]
            });

            const commandEncoder = device.createCommandEncoder();
            const passEncoder = commandEncoder.beginComputePass();
            passEncoder.setPipeline(pipeline);
            passEncoder.setBindGroup(0, bindGroup);
            passEncoder.dispatchWorkgroups(Math.ceil(N / 8), Math.ceil(N / 8));
            passEncoder.end();
            commandEncoder.copyBufferToBuffer(bufferC, 0, bufferRead, 0, size * 3 * 4);
            device.queue.submit([commandEncoder.finish()]);

            await bufferRead.mapAsync(GPUMapMode.READ);
            const result = new Float32Array(bufferRead.getMappedRange().slice(0));
            bufferRead.unmap();

            bufferA.destroy(); bufferB.destroy(); bufferC.destroy(); bufferRead.destroy(); uniformBuffer.destroy();
            return result;
        }
    </script>
</body>
</html>
